{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from OSUDataset import OsuDataset, collate_fn\n",
    "from utils.DatasetGenerator import get_X, get_pos_sequences, get_key_sequences\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kq836\\AppData\\Local\\Temp\\ipykernel_16528\\3660366898.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  eval_model_pos.load_state_dict(torch.load(f'./OSU_model_pos_{pos_version}.pth'))\n",
      "C:\\Users\\kq836\\AppData\\Local\\Temp\\ipykernel_16528\\3660366898.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  eval_model_key.load_state_dict(torch.load(f'./OSU_model_key_{key_version}.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OSUModelKey(\n",
       "  (key_encoder): KeypressEncoder(\n",
       "    (lstm): LSTM(4, 16, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (key_decoder): KeypressDecoder(\n",
       "    (lstm): LSTM(2, 16, num_layers=2, batch_first=True)\n",
       "    (key): Linear(in_features=16, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from OSUModel import OSUModelPos, OSUModelKey, PositionEncoder, KeypressEncoder, PositionDecoder, KeypressDecoder\n",
    "pos_version = '0.7'\n",
    "key_version = '0.3'\n",
    "\n",
    "pos_input_size = 10\n",
    "pos_hidden_size = 24\n",
    "pos_num_layers = 2\n",
    "\n",
    "key_input_size = 4\n",
    "key_hidden_size = 16\n",
    "key_num_layers = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "eval_pos_encoder = PositionEncoder(pos_input_size, pos_hidden_size, pos_num_layers).to(device)\n",
    "eval_pos_decoder = PositionDecoder(pos_hidden_size, pos_num_layers).to(device)\n",
    "eval_model_pos = OSUModelPos(eval_pos_encoder, eval_pos_decoder, device).to(device)\n",
    "eval_model_pos.load_state_dict(torch.load(f'./OSU_model_pos_{pos_version}.pth'))\n",
    "eval_model_pos.eval()\n",
    "\n",
    "eval_key_encoder = KeypressEncoder(key_input_size, key_hidden_size, key_num_layers).to(device)\n",
    "eval_key_decoder = KeypressDecoder(key_hidden_size, key_num_layers).to(device)\n",
    "eval_model_key = OSUModelKey(eval_key_encoder, eval_key_decoder, device).to(device)\n",
    "eval_model_key.load_state_dict(torch.load(f'./OSU_model_key_{key_version}.pth'))\n",
    "eval_model_key.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position Dataset\n",
    "N = 3\n",
    "react_time = 400\n",
    "test_data_path = '../Data/unseen/OOPARTS'\n",
    "hr = False\n",
    "X_test = get_X(test_data_path, hr)\n",
    "start_time = X_test['time'].min() - react_time\n",
    "pos_input_sequence, pos_time_steps = get_pos_sequences([X_test, None, test_data_path], N, react_time)\n",
    "dummy_pos_target = torch.zeros(1, 2)\n",
    "pos_target_sequence = [dummy_pos_target for i in range(len(pos_input_sequence))]\n",
    "\n",
    "pos_dataset = OsuDataset(pos_input_sequence, pos_target_sequence)\n",
    "pos_loader =  DataLoader(pos_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 22243/22243 [00:21<00:00, 1016.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Position prediction\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "position_pred = []\n",
    "with torch.no_grad():\n",
    "    # initialize the first position sequence predictions\n",
    "    # Cursor will be center (0.5, 0.5)\n",
    "    prev_pred = torch.tensor([0.5, 0.5], device=device).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "    for idx, (input_sequence, target_sequence, input_length, target_length) in tqdm(enumerate(pos_loader), total=len(pos_loader), desc=\"Predicting\"):\n",
    "        input_sequence, target_sequence = input_sequence.to(device), target_sequence.to(device)\n",
    "        \n",
    "        # # appending relative distance\n",
    "        # # **Unpack the input_sequence**\n",
    "        # padded_input_sequence, input_lengths = pad_packed_sequence(input_sequence, batch_first=True)\n",
    "        # # padded_input_sequence shape: (batch_size, seq_len, feature_size)\n",
    "        \n",
    "        # prev_position = prev_pred.squeeze(0).squeeze(0)  # Shape: (2,)\n",
    "        # dist_x = torch.abs(padded_input_sequence[:, :, 0] - prev_position[0])  # Shape: (batch_size, seq_len)\n",
    "        # dist_y = torch.abs(padded_input_sequence[:, :, 1] - prev_position[1])  # Shape: (batch_size, seq_len)\n",
    "        \n",
    "        # # **Append distances to input_sequence**\n",
    "        # # Add an extra dimension to dist_x and dist_y to match dimensions for concatenation\n",
    "        # dist_x = dist_x.unsqueeze(2)  # Shape: (batch_size, seq_len, 1)\n",
    "        # dist_y = dist_y.unsqueeze(2)  # Shape: (batch_size, seq_len, 1)\n",
    "        \n",
    "        # # Concatenate along the feature dimension (dim=2)\n",
    "        # new_input_sequence = torch.cat((padded_input_sequence, dist_x, dist_y), dim=2)\n",
    "        # # new_input_sequence shape: (batch_size, seq_len, feature_size + 2)\n",
    "        \n",
    "        # new_input_sequence_packed = pack_padded_sequence(new_input_sequence, input_lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # appending previous prediction\n",
    "        target = torch.cat((prev_pred, target_sequence), dim=1)\n",
    "        \n",
    "        pos_output = eval_model_pos(input_sequence, target, 0)\n",
    "        \n",
    "        prev_pred = pos_output\n",
    "        \n",
    "        position_pred.append(pos_output.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keypress Dataset\n",
    "N = 10\n",
    "react_time = 500\n",
    "key_input_sequence, key_time_steps, key_end_times = get_key_sequences([X_test, None, test_data_path], N, react_time)\n",
    "dummy_key_target = torch.zeros(1, 2)\n",
    "key_target_sequence = [dummy_key_target for i in range(len(key_input_sequence))]\n",
    "\n",
    "key_dataset = OsuDataset(key_input_sequence, key_target_sequence)\n",
    "key_loader =  DataLoader(key_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2500/2500 [00:02<00:00, 911.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Keypress prediction\n",
    "keypress_pred = []\n",
    "with torch.no_grad():\n",
    "    # initialize the first keypress sequence predictions\n",
    "    # Keypress will be key1 (1.0, 0.0)\n",
    "    prev_pred = torch.tensor([1.0, 0.0], device=device).unsqueeze(0).unsqueeze(1)\n",
    "    \n",
    "    for idx, (input_sequence, target_sequence, input_length, target_length) in tqdm(enumerate(key_loader), total=len(key_loader), desc=\"Predicting\"):\n",
    "        input_sequence, target_sequence = input_sequence.to(device), target_sequence.to(device)\n",
    "            \n",
    "        target = torch.cat((prev_pred, target_sequence), dim=1)\n",
    "        key_output = eval_model_key(input_sequence, target, 0)\n",
    "        \n",
    "        prev_pred = key_output\n",
    "        \n",
    "        key_index = torch.argmax(key_output, 2)\n",
    "        keypress_pred.append(key_index.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Processing\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "positions = np.array(position_pred)\n",
    "positions[:, 0] *= 512\n",
    "positions[:, 1] *= 384\n",
    "\n",
    "pos_time_column = np.array(pos_time_steps)\n",
    "pos_time_column = (pos_time_column).astype(int)\n",
    "pos_time_column = pos_time_column.reshape(-1, 1)\n",
    "positions_matrix= np.concatenate((pos_time_column, positions), axis=1)\n",
    "\n",
    "keypresses = np.array(keypress_pred)\n",
    "keypresses = keypresses + 1\n",
    "key_time_column = np.array(key_time_steps).astype(int)\n",
    "key_time_column = key_time_column.reshape(-1, 1)\n",
    "key_end_time_column = np.array(key_end_times).astype(int)\n",
    "key_end_time_column = key_end_time_column.reshape(-1, 1)\n",
    "keypresses_matrix = np.concatenate((key_time_column, key_end_time_column, keypresses), axis=1)\n",
    "\n",
    "\n",
    "def interpolate_data(data):\n",
    "    time = data[:, 0]\n",
    "    x = data[:, 1]\n",
    "    y = data[:, 2]\n",
    "\n",
    "    dt = np.diff(time)\n",
    "    gap_threshold = 25  # milliseconds\n",
    "    gap_indices = np.where(dt > gap_threshold)[0]\n",
    "\n",
    "    # Define segment start and end indices\n",
    "    segment_starts = np.insert(gap_indices + 1, 0, 0)\n",
    "    segment_ends = np.append(gap_indices, len(time) - 1)\n",
    "\n",
    "    interpolated_time = []\n",
    "    interpolated_x = []\n",
    "    interpolated_y = []\n",
    "\n",
    "    # Desired sampling interval (approximate 120Hz)\n",
    "    sampling_interval = 8  # milliseconds\n",
    "\n",
    "    for start_idx, end_idx in zip(segment_starts, segment_ends):\n",
    "        segment_time = time[start_idx:end_idx + 1]\n",
    "        segment_x = x[start_idx:end_idx + 1]\n",
    "        segment_y = y[start_idx:end_idx + 1]\n",
    "\n",
    "        # Round segment times to integers\n",
    "        segment_start_time = int(np.ceil(segment_time[0]))\n",
    "        segment_end_time = int(np.floor(segment_time[-1]))\n",
    "\n",
    "        # Create new integer time points at the desired sampling interval\n",
    "        new_time = np.arange(segment_start_time, segment_end_time + 1, sampling_interval)\n",
    "\n",
    "        if len(new_time) == 0:\n",
    "            continue  # No new time points in this segment\n",
    "\n",
    "        # Choose interpolation kind\n",
    "        kind = 'cubic' if len(segment_time) >= 4 else 'linear'\n",
    "\n",
    "        # Interpolate x and y values\n",
    "        x_interp = interp1d(segment_time, segment_x, kind=kind)\n",
    "        y_interp = interp1d(segment_time, segment_y, kind=kind)\n",
    "\n",
    "        new_x = x_interp(new_time)\n",
    "        new_y = y_interp(new_time)\n",
    "\n",
    "        # Collect interpolated data\n",
    "        interpolated_time.append(new_time)\n",
    "        interpolated_x.append(new_x)\n",
    "        interpolated_y.append(new_y)\n",
    "\n",
    "    # Combine all segments\n",
    "    final_time = np.concatenate(interpolated_time)\n",
    "    final_x = np.concatenate(interpolated_x)\n",
    "    final_y = np.concatenate(interpolated_y)\n",
    "\n",
    "    # Combine into final data array\n",
    "    final_data = np.column_stack((final_time, final_x, final_y))\n",
    "    return final_data\n",
    "\n",
    "def merge_positions_keypresses(positions_matrix, keypresses_matrix):\n",
    "    # Copy positions_matrix to avoid modifying the original\n",
    "    # positions_matrix = positions_matrix.copy()\n",
    "    \n",
    "    # Initialize lists to collect new rows and indices to update\n",
    "    new_rows = []\n",
    "    update_indices = []\n",
    "    \n",
    "    # Iterate over each keypress event\n",
    "    for keypress in keypresses_matrix:\n",
    "        keypress_time, end_time, keycode = keypress\n",
    "        keypress_time = float(keypress_time)\n",
    "        end_time = float(end_time)\n",
    "        keycode = int(keycode)\n",
    "        \n",
    "        # Find indices in positions_matrix where time matches\n",
    "        idx = np.searchsorted(positions_matrix[:, 0], keypress_time, side='left')\n",
    "        \n",
    "        # Handle end_time == -1 (immediate release)\n",
    "        if end_time == -1:\n",
    "            # Check if positions_matrix has a row at keypress_time\n",
    "            if idx < len(positions_matrix) and positions_matrix[idx, 0] == keypress_time:\n",
    "                # Update keycode at this index\n",
    "                update_indices.append((idx, keycode))\n",
    "            else:\n",
    "                # Insert new row with previous x, y, and keycode\n",
    "                if idx > 0:\n",
    "                    x_prev = positions_matrix[idx - 1, 1]\n",
    "                    y_prev = positions_matrix[idx - 1, 2]\n",
    "                else:\n",
    "                    x_prev = positions_matrix[0, 1]\n",
    "                    y_prev = positions_matrix[0, 2]\n",
    "                new_row = [keypress_time, x_prev, y_prev, keycode]\n",
    "                new_rows.append(new_row)\n",
    "        else:\n",
    "            # Find start and end indices for the time range\n",
    "            idx_start = np.searchsorted(positions_matrix[:, 0], keypress_time, side='left')\n",
    "            idx_end = np.searchsorted(positions_matrix[:, 0], end_time, side='left')\n",
    "            \n",
    "            # Update keycodes in the time range\n",
    "            for idx_range in range(idx_start, idx_end):\n",
    "                update_indices.append((idx_range, keycode))\n",
    "            \n",
    "            # Check if positions_matrix has a row at keypress_time\n",
    "            if idx_start >= len(positions_matrix) or positions_matrix[idx_start, 0] != keypress_time:\n",
    "                if idx_start > 0:\n",
    "                    x_prev = positions_matrix[idx_start - 1, 1]\n",
    "                    y_prev = positions_matrix[idx_start - 1, 2]\n",
    "                else:\n",
    "                    x_prev = positions_matrix[0, 1]\n",
    "                    y_prev = positions_matrix[0, 2]\n",
    "                new_row = [keypress_time, x_prev, y_prev, keycode]\n",
    "                new_rows.append(new_row)\n",
    "    \n",
    "    # Update the keycodes in positions_matrix\n",
    "    for idx, keycode in update_indices:\n",
    "        positions_matrix[idx, 3] = keycode\n",
    "    \n",
    "    # Convert new_rows to a numpy array if any new rows exist\n",
    "    if new_rows:\n",
    "        new_rows_array = np.array(new_rows)\n",
    "        # Combine the original and new positions\n",
    "        positions_matrix = np.vstack((positions_matrix, new_rows_array))\n",
    "        # Sort the combined positions by time\n",
    "        positions_matrix = positions_matrix[np.argsort(positions_matrix[:, 0])]\n",
    "    \n",
    "    return positions_matrix\n",
    "\n",
    "poistions_matrix_interpolated = interpolate_data(positions_matrix)\n",
    "num_rows = poistions_matrix_interpolated.shape[0]\n",
    "dummy_keys_column = np.zeros((num_rows, 1))\n",
    "poistions_matrix_interpolated = np.concatenate((poistions_matrix_interpolated, dummy_keys_column), axis=1)\n",
    "replay_predictions = merge_positions_keypresses(poistions_matrix_interpolated, keypresses_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# # Visualizing\n",
    "# from utils.Visualizer import visualize\n",
    "# from utils.DataParser import parse_map\n",
    "# from pathlib import Path\n",
    "\n",
    "# map_path = list(Path(test_data_path).glob('*.osu'))[0]\n",
    "# map_data, _ = parse_map(map_path)\n",
    "# song = list(Path(test_data_path).glob('audio.*'))[0]\n",
    "\n",
    "# visualize(map_data, replay_predictions, song)\n",
    "\n",
    "\n",
    "\n",
    "# positions_times = replay_predictions[:, 0]\n",
    "\n",
    "# for i in range(keypresses_matrix.shape[0]):\n",
    "#     kp_time = keypresses_matrix[i, 0]\n",
    "#     kp_end_time = keypresses_matrix[i, 1]\n",
    "#     kp_keycode = keypresses_matrix[i, 2]\n",
    "    \n",
    "#     if kp_end_time == -1:\n",
    "#         # Find the index in positions_matrix where the time is closest to kp_time\n",
    "#         abs_diff = np.abs(positions_times - kp_time)\n",
    "#         index = np.argmin(abs_diff)\n",
    "#         replay_predictions[index, 3] = kp_keycode\n",
    "#     else:\n",
    "#         # Find indices where positions_times are between kp_time and kp_end_time\n",
    "#         indices = np.where((positions_times >= kp_time) & (positions_times <= kp_end_time))[0]\n",
    "#         replay_predictions[indices, 3] = kp_keycode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting replay\n",
    "from osrparse import Replay\n",
    "from osrparse.utils import ReplayEventOsu, Key\n",
    "from pathlib import Path\n",
    "\n",
    "replay_path = list(Path(test_data_path).glob('*.osr'))[0]\n",
    "replay = Replay.from_path(replay_path)\n",
    "\n",
    "time_deltas = np.diff(replay_predictions[:, 0], prepend=replay_predictions[0, 0])\n",
    "time_deltas[0] = replay_predictions[0, 0]\n",
    "\n",
    "keymap = [0, 1, 2, 11]\n",
    "replay_data = []\n",
    "for i in range(len(replay_predictions)):\n",
    "    pred = replay_predictions[i]\n",
    "    key = Key(keymap[int(pred[3])])\n",
    "    replay_event = ReplayEventOsu(int(time_deltas[i]), float(pred[1]), float(pred[2]), key)\n",
    "    replay_data.append(replay_event)\n",
    "    \n",
    "markers = [\n",
    "    ReplayEventOsu(0, 256.0, -500.0, Key(0)),\n",
    "    ReplayEventOsu(-1, 256.0, -500.0, Key(0))\n",
    "]\n",
    "\n",
    "replay.replay_data = markers + replay_data\n",
    "replay.username = f'Model_P{pos_version}_K{key_version}'\n",
    "\n",
    "replay.write_path(f\"{test_data_path}/predictions_{pos_version}_{key_version}.osr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
