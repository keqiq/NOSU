{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "# sys.path.append(str(Path.cwd().parent))\n",
    "# from utils.DatasetGenerator import get_X, get_y, get_pos_sequences, read_sequences\n",
    "# path = '../Data/train_pos/annoy'\n",
    "# df_y_pos, hr = get_y(path, 'pos')\n",
    "# df_X = get_X(path, hr)\n",
    "# get_pos_sequences([df_X, df_y_pos, path], 10, 500)\n",
    "# input_seq, target_seq = read_sequences(path, 'pos')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "# sys.path.append(str(Path.cwd().parent))\n",
    "# from utils.Visualizer import visualize\n",
    "# from utils.DataParser import parse_map, parse_replay_pos\n",
    "# path = '../Data/train_pos/ty/'\n",
    "# replay_path = list(Path(path).glob('*.osr'))[0]\n",
    "# map_path = list(Path(path).glob('*.osu'))[0]\n",
    "# replay_data, hr = parse_replay_pos(replay_path)\n",
    "# hit_objects, _ = parse_map(map_path, hr)\n",
    "# song = list(Path(path).glob('audio.*'))[0]\n",
    "# visualize(hit_objects, replay_data, song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "%load_ext autoreload\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "data_paths = {\n",
    "    'train': '../Data/train_pos',\n",
    "    'valid': '../Data/valid_pos'\n",
    "}\n",
    "REGENERATE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "# Data parsing\n",
    "from utils.DatasetGenerator import get_set\n",
    "datasets = {\n",
    "    'train': None,\n",
    "    'valid': None\n",
    "}\n",
    "\n",
    "for idx, set in enumerate(data_paths):\n",
    "    print(f'Converting {set} data')\n",
    "    data = get_set(data_paths[set], 'pos', REGENERATE)\n",
    "    \n",
    "    datasets[set] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving train sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:30<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sequence generation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*weights_only=False.*\")\n",
    "from utils.DatasetGenerator import create_set_sequences, get_set_sequences\n",
    "from itertools import chain\n",
    "\n",
    "N = 3\n",
    "window = 400\n",
    "for idx, set in enumerate(datasets):\n",
    "    if len(datasets[set]) > 0:\n",
    "        print(f'Generating {set} sequences')\n",
    "        create_set_sequences(datasets[set], N, window, 'pos')\n",
    "\n",
    "combined_train_key_input = None\n",
    "combined_train_key_target = None\n",
    "valid_sequences = None\n",
    "for idx, set in enumerate(data_paths):\n",
    "    print(f'Retrieving {set} sequences')\n",
    "    key_input_sequences, key_target_sequences = get_set_sequences(data_paths[set], 'pos')\n",
    "    if set == 'train':\n",
    "        combined_train_key_input = list(chain.from_iterable(key_input_sequences))\n",
    "        combined_train_key_target = list(chain.from_iterable(key_target_sequences))\n",
    "    else:\n",
    "        valid_sequences = [key_input_sequences, key_target_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from Model.OSUDataset import OsuDataset, collate_fn\n",
    "data_paths = {\n",
    "    'train': '../Data/train_pos',\n",
    "    'valid': '../Data/valid_pos'\n",
    "}\n",
    "BATCH_SIZE_TRAIN = 1024\n",
    "if os.path.exists('./pos_dataset/train_dataset.pth') and not REGENERATE:\n",
    "    train_dataset = torch.load('./pos_dataset/train_dataset.pth')\n",
    "else:\n",
    "    train_dataset = OsuDataset(combined_train_key_input, combined_train_key_target)\n",
    "    torch.save(train_dataset, './pos_dataset/train_dataset.pth')\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, drop_last=True, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "BATCH_SIZE_VALID = 64\n",
    "valid_loaders = []\n",
    "valid_folders = os.listdir(data_paths['valid'])\n",
    "valid_data_size = sum(os.path.isdir(os.path.join(data_paths['valid'], folder)) for folder in valid_folders)\n",
    "for idx in range(valid_data_size):\n",
    "    if os.path.exists(f'./pos_dataset/valid_dataset_{idx}.pth') and not REGENERATE:\n",
    "        valid_dataset = torch.load(f'./pos_dataset/valid_dataset_{idx}.pth')\n",
    "    else:\n",
    "        valid_dataset = valid_dataset = OsuDataset(valid_sequences[0][idx], valid_sequences[1][idx])\n",
    "        torch.save(valid_dataset, f'./pos_dataset/valid_dataset_{idx}.pth')\n",
    "        \n",
    "    valid_loader =  DataLoader(valid_dataset, batch_size=BATCH_SIZE_VALID, shuffle=False, drop_last=True, collate_fn=collate_fn, pin_memory=True)\n",
    "    valid_loaders.append(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from Model.OSUModel import PositionEncoder, PositionDecoder, OSUModelPos\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "pos_input_size = 10\n",
    "\n",
    "pos_hidden_size = 24\n",
    "pos_num_layers = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Encoders take (input_size, hidden_size, num_layers)\n",
    "pos_encoder = PositionEncoder(pos_input_size, pos_hidden_size, pos_num_layers).to(device)\n",
    "\n",
    "# Decoders takes (hidden_size, num_layers)\n",
    "pos_decoder = PositionDecoder(pos_hidden_size, pos_num_layers).to(device)\n",
    "\n",
    "osuModelPos = OSUModelPos(pos_encoder, pos_decoder, device).to(device)\n",
    "\n",
    "pos_criterion = nn.L1Loss(reduction='none')\n",
    "\n",
    "pos_optimizer = torch.optim.Adam(\n",
    "    osuModelPos.parameters(),\n",
    "    lr = 0.01,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "\n",
    "pos_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(pos_optimizer, mode='min',\n",
    "                                                    factor=0.1, patience=15,\n",
    "                                                    threshold=1e-4)\n",
    "\n",
    "# def masked_loss_pos(pos_inputs, pos_outputs, targets, target_lengths, threshold = 0.20, base_scaling_factor = 2.0):\n",
    "#   # Position targets: skip the first target to align with pos_outputs\n",
    "#     pos_targets = targets[:, 1:, :]  # Shape: (batch_size, seq_len - 1, 2)\n",
    "#     target_lengths = target_lengths.to(pos_outputs.device)\n",
    "#     # Create mask for variable length sequences\n",
    "#     max_len = pos_outputs.size(1)  # seq_len - 1\n",
    "#     mask = torch.arange(max_len, device=pos_outputs.device).unsqueeze(0) < target_lengths.unsqueeze(1)\n",
    "#     # Shape: (batch_size, seq_len - 1)\n",
    "\n",
    "#     # Compute the position loss using L1 loss without reduction\n",
    "#     pos_loss = pos_criterion(pos_outputs, pos_targets)  # Shape: (batch_size, seq_len - 1, 2)\n",
    "#     pos_loss = pos_loss.sum(dim=2)  # Sum over position dimensions (x and y), shape: (batch_size, seq_len - 1)\n",
    "\n",
    "#     # Unpack pos_inputs to get time_values\n",
    "#     padded_inputs, input_lengths = pad_packed_sequence(pos_inputs, batch_first=True)\n",
    "#     # padded_inputs shape: (batch_size, seq_len, 10)\n",
    "\n",
    "#     # Extract time values from column index 7 (8th column)\n",
    "#     # We are interested in the first two entries of each sequence\n",
    "#     time_values = padded_inputs[:, :2, 7]  # Shape: (batch_size, 2)\n",
    "\n",
    "#     # Compute absolute time values\n",
    "#     abs_time_values = torch.abs(time_values)  # Shape: (batch_size, 2)\n",
    "    \n",
    "#     # Find the smallest absolute time value for each sample in the batch\n",
    "#     min_abs_time_values, _ = torch.min(abs_time_values, dim=1)  # Shape: (batch_size,)\n",
    "    \n",
    "#     # Compute scaling factors based on time_values\n",
    "#     scaling_factor = torch.ones_like(time_values, device=pos_outputs.device)  # Initialize with ones\n",
    "#     time_mask = time_values <= threshold  # Boolean mask where time_value <= threshold\n",
    "\n",
    "#     # Compute scaling factors for time_values <= threshold\n",
    "#     scaling_factor[time_mask] = 1.0 + (threshold - time_values[time_mask]) * ((base_scaling_factor - 1.0) / threshold)\n",
    "#     # Ensure scaling_factor is at least 1.0\n",
    "\n",
    "#     # Apply scaling factors to pos_loss\n",
    "#     pos_loss = pos_loss * scaling_factor\n",
    "\n",
    "#     # Apply the sequence mask\n",
    "#     pos_loss = (pos_loss * mask).sum() / mask.sum()\n",
    "\n",
    "#     return pos_loss\n",
    "  \n",
    "def masked_loss_pos(pos_outputs, targets, target_lengths):\n",
    "    # Position targets (batch_size, sequence_len - 1, 2)\n",
    "    pos_targets = targets[:, 1:, :]\n",
    "\n",
    "    # Creating mask for variable length sequences\n",
    "    max_len = pos_outputs.size(1)\n",
    "    #(batch_size, max_len). True when value is less than target length\n",
    "    mask = torch.arange(max_len).unsqueeze(0) < target_lengths.unsqueeze(1) \n",
    "    mask = mask.to(pos_outputs.device)\n",
    "\n",
    "    # Position loss with absolute error.\n",
    "    pos_loss = pos_criterion(pos_outputs, pos_targets)\n",
    "    pos_loss = pos_loss.sum(dim=2)\n",
    "    pos_loss = (pos_loss * mask).sum() / mask.sum()\n",
    "\n",
    "    return pos_loss\n",
    "  \n",
    "# def get_pos_loss(pos_outputs, targets):\n",
    "#     # Position targets (batch_size, 2, 2)\n",
    "#     # Removing previous positions from targets\n",
    "#     pos_targets = targets[:, 1:, :]  \n",
    "\n",
    "#     # Position loss with absolute error\n",
    "#     pos_loss = pos_criterion(pos_outputs, pos_targets)\n",
    "    \n",
    "#     # Sum the loss along the last dimension and compute the mean over the batch\n",
    "#     pos_loss = pos_loss.sum(dim=2).mean()\n",
    "\n",
    "#     return pos_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]T Loss Pos: 0.0807 | V Loss Pos: 0.0367 | LR Pos: 0.01 | TFR: 1.00\n",
      "Epoch [2/1000]T Loss Pos: 0.0309 | V Loss Pos: 0.0311 | LR Pos: 0.01 | TFR: 0.95\n",
      "Epoch [3/1000]T Loss Pos: 0.0254 | V Loss Pos: 0.0336 | LR Pos: 0.01 | TFR: 0.90\n",
      "Epoch [4/1000]T Loss Pos: 0.0238 | V Loss Pos: 0.0250 | LR Pos: 0.01 | TFR: 0.85\n",
      "Epoch [5/1000]T Loss Pos: 0.0215 | V Loss Pos: 0.0251 | LR Pos: 0.01 | TFR: 0.80\n",
      "Epoch [6/1000]T Loss Pos: 0.0211 | V Loss Pos: 0.0257 | LR Pos: 0.01 | TFR: 0.75\n",
      "Epoch [7/1000]T Loss Pos: 0.0210 | V Loss Pos: 0.0244 | LR Pos: 0.01 | TFR: 0.70\n",
      "Epoch [8/1000]T Loss Pos: 0.0192 | V Loss Pos: 0.0233 | LR Pos: 0.01 | TFR: 0.65\n",
      "Epoch [9/1000]T Loss Pos: 0.0198 | V Loss Pos: 0.0235 | LR Pos: 0.01 | TFR: 0.60\n",
      "Epoch [10/1000]T Loss Pos: 0.0203 | V Loss Pos: 0.0265 | LR Pos: 0.01 | TFR: 0.55\n",
      "Epoch [11/1000]T Loss Pos: 0.0202 | V Loss Pos: 0.0230 | LR Pos: 0.01 | TFR: 0.50\n",
      "Epoch [12/1000]T Loss Pos: 0.0182 | V Loss Pos: 0.0243 | LR Pos: 0.01 | TFR: 0.45\n",
      "Epoch [13/1000]T Loss Pos: 0.0183 | V Loss Pos: 0.0234 | LR Pos: 0.01 | TFR: 0.40\n",
      "Epoch [14/1000]T Loss Pos: 0.0179 | V Loss Pos: 0.0231 | LR Pos: 0.01 | TFR: 0.35\n",
      "Epoch [15/1000]T Loss Pos: 0.0180 | V Loss Pos: 0.0231 | LR Pos: 0.01 | TFR: 0.30\n",
      "Epoch [16/1000]T Loss Pos: 0.0181 | V Loss Pos: 0.0237 | LR Pos: 0.01 | TFR: 0.25\n",
      "Epoch [17/1000]T Loss Pos: 0.0177 | V Loss Pos: 0.0234 | LR Pos: 0.01 | TFR: 0.20\n",
      "Epoch [18/1000]T Loss Pos: 0.0178 | V Loss Pos: 0.0236 | LR Pos: 0.01 | TFR: 0.15\n",
      "Epoch [19/1000]T Loss Pos: 0.0177 | V Loss Pos: 0.0221 | LR Pos: 0.01 | TFR: 0.10\n",
      "Epoch [20/1000]T Loss Pos: 0.0184 | V Loss Pos: 0.0237 | LR Pos: 0.01 | TFR: 0.05\n",
      "Epoch [21/1000]T Loss Pos: 0.0173 | V Loss Pos: 0.0232 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [22/1000]T Loss Pos: 0.0172 | V Loss Pos: 0.0237 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [23/1000]T Loss Pos: 0.0174 | V Loss Pos: 0.0222 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [24/1000]T Loss Pos: 0.0171 | V Loss Pos: 0.0225 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [25/1000]T Loss Pos: 0.0169 | V Loss Pos: 0.0224 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [26/1000]T Loss Pos: 0.0174 | V Loss Pos: 0.0242 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [27/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0225 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [28/1000]T Loss Pos: 0.0173 | V Loss Pos: 0.0218 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [29/1000]T Loss Pos: 0.0169 | V Loss Pos: 0.0225 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [30/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0216 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [31/1000]T Loss Pos: 0.0171 | V Loss Pos: 0.0242 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [32/1000]T Loss Pos: 0.0171 | V Loss Pos: 0.0228 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [33/1000]T Loss Pos: 0.0166 | V Loss Pos: 0.0222 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [34/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0218 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [35/1000]T Loss Pos: 0.0169 | V Loss Pos: 0.0226 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [36/1000]T Loss Pos: 0.0169 | V Loss Pos: 0.0217 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [37/1000]T Loss Pos: 0.0166 | V Loss Pos: 0.0220 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [38/1000]T Loss Pos: 0.0167 | V Loss Pos: 0.0223 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [39/1000]T Loss Pos: 0.0175 | V Loss Pos: 0.0224 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [40/1000]T Loss Pos: 0.0165 | V Loss Pos: 0.0233 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [41/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0226 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [42/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0225 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [43/1000]T Loss Pos: 0.0167 | V Loss Pos: 0.0217 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [44/1000]T Loss Pos: 0.0166 | V Loss Pos: 0.0225 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [45/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0214 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [46/1000]T Loss Pos: 0.0167 | V Loss Pos: 0.0215 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [47/1000]T Loss Pos: 0.0166 | V Loss Pos: 0.0226 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [48/1000]T Loss Pos: 0.0167 | V Loss Pos: 0.0227 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [49/1000]T Loss Pos: 0.0166 | V Loss Pos: 0.0221 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [50/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0216 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [51/1000]T Loss Pos: 0.0166 | V Loss Pos: 0.0219 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [52/1000]T Loss Pos: 0.0169 | V Loss Pos: 0.0222 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [53/1000]T Loss Pos: 0.0166 | V Loss Pos: 0.0219 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [54/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0221 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [55/1000]T Loss Pos: 0.0168 | V Loss Pos: 0.0219 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [56/1000]T Loss Pos: 0.0167 | V Loss Pos: 0.0232 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [57/1000]T Loss Pos: 0.0167 | V Loss Pos: 0.0222 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [58/1000]T Loss Pos: 0.0167 | V Loss Pos: 0.0262 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [59/1000]T Loss Pos: 0.0169 | V Loss Pos: 0.0219 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [60/1000]T Loss Pos: 0.0165 | V Loss Pos: 0.0221 | LR Pos: 0.01 | TFR: 0.00\n",
      "Epoch [61/1000]T Loss Pos: 0.0167 | V Loss Pos: 0.0225 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [62/1000]T Loss Pos: 0.0154 | V Loss Pos: 0.0213 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [63/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0212 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [64/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0211 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [65/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0213 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [66/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0214 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [67/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0215 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [68/1000]T Loss Pos: 0.0154 | V Loss Pos: 0.0211 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [69/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0212 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [70/1000]T Loss Pos: 0.0154 | V Loss Pos: 0.0215 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [71/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0214 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [72/1000]T Loss Pos: 0.0154 | V Loss Pos: 0.0215 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [73/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0211 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [74/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0211 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [75/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0215 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [76/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0211 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [77/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0213 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [78/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0214 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [79/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0214 | LR Pos: 0.001 | TFR: 0.00\n",
      "Epoch [80/1000]T Loss Pos: 0.0153 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [81/1000]T Loss Pos: 0.0152 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [82/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [83/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [84/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [85/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [86/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [87/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [88/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [89/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [90/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [91/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [92/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [93/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [94/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [95/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 0.0001 | TFR: 0.00\n",
      "Epoch [96/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [97/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [98/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [99/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [100/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [101/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [102/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [103/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [104/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [105/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [106/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [107/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [108/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0212 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [109/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [110/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [111/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1e-05 | TFR: 0.00\n",
      "Epoch [112/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [113/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [114/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [115/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [116/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [117/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [118/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [119/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [120/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [121/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [122/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [123/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n",
      "Epoch [124/1000]T Loss Pos: 0.0151 | V Loss Pos: 0.0211 | LR Pos: 1.0000000000000002e-06 | TFR: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m teacher_forcing_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (epoch \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m20\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\Model\\OSUDataset.py:42\u001b[0m, in \u001b[0;36mcollate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Padding\u001b[39;00m\n\u001b[0;32m     41\u001b[0m input_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m inputs])\n\u001b[1;32m---> 42\u001b[0m padded_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m target_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m targets])\n\u001b[0;32m     45\u001b[0m padded_targets \u001b[38;5;241m=\u001b[39m pad_sequence(targets, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\nn\\utils\\rnn.py:397\u001b[0m, in \u001b[0;36mpad_sequence\u001b[1;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[0;32m    393\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "total_train_len = len(train_loader)\n",
    "total_valid_len = 0\n",
    "for valid_loader in valid_loaders:\n",
    "    total_valid_len += len(valid_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    osuModelPos.train()\n",
    "    train_loss_pos = 0\n",
    "    teacher_forcing_ratio = max(1 - (epoch / 20), 0)\n",
    "    \n",
    "    # Training\n",
    "    for train_inputs, train_targets, input_lengths, target_lengths in train_loader:\n",
    "        train_inputs, train_targets = train_inputs.to(device), train_targets.to(device)\n",
    "        \n",
    "        pos_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagate\n",
    "        train_pos_outputs = osuModelPos(train_inputs, train_targets, teacher_forcing_ratio)\n",
    "        \n",
    "        # Compute losses\n",
    "        # loss_pos = get_pos_loss(train_pos_outputs, train_targets)\n",
    "        loss_pos = masked_loss_pos(train_pos_outputs, train_targets, target_lengths)\n",
    "        \n",
    "        # Accumulate losses\n",
    "        train_loss_pos += loss_pos.item()\n",
    "        \n",
    "        # Position encoder decoder back propagation\n",
    "        loss_pos.backward()\n",
    "        \n",
    "        # Gradient clipping \n",
    "        torch.nn.utils.clip_grad_norm_(osuModelPos.parameters(), max_norm=1.0)\n",
    "        # Updating weights\n",
    "        pos_optimizer.step()\n",
    "        \n",
    "    train_loss_pos /= total_train_len\n",
    "    \n",
    "    # Validation\n",
    "    osuModelPos.eval()\n",
    "    total_valid_loss_pos = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for valid_loader in valid_loaders:\n",
    "            valid_loss_pos = 0\n",
    "            valid_loss_key = 0\n",
    "            for valid_inputs, valid_targets, input_lengths, target_lengths in valid_loader:\n",
    "                valid_inputs, valid_targets = valid_inputs.to(device), valid_targets.to(device)\n",
    "\n",
    "                valid_pos_outputs = osuModelPos(valid_inputs, valid_targets, 0)\n",
    "                \n",
    "                # loss_pos = get_pos_loss(valid_pos_outputs, valid_targets)\n",
    "                loss_pos = masked_loss_pos(valid_pos_outputs, valid_targets, target_lengths)\n",
    "                valid_loss_pos += loss_pos.item()\n",
    "                \n",
    "            total_valid_loss_pos += valid_loss_pos\n",
    "            \n",
    "    total_valid_loss_pos /= total_valid_len\n",
    "    \n",
    "    pos_scheduler.step(total_valid_loss_pos)\n",
    "    \n",
    "    pos_lr = pos_optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Printing info\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\"\n",
    "    f\"T Loss Pos: {train_loss_pos:.4f} | \"\n",
    "    f\"V Loss Pos: {total_valid_loss_pos:.4f} | \"\n",
    "    f\"LR Pos: {pos_lr} | \"\n",
    "    f\"TFR: {teacher_forcing_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '0.7'\n",
    "torch.save(osuModelPos.state_dict(), f'./OSU_model_pos_{VERSION}.pth')     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
