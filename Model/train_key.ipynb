{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.DatasetGenerator import get_X, get_y, get_key_sequences, read_sequences\n",
    "path = '../Data/train_key/beyond'\n",
    "df_X = get_X(path)\n",
    "df_y_key = get_y(path, 'key')\n",
    "get_key_sequences([df_X, df_y_key, path], 10, 500)\n",
    "input_seq, target_seq = read_sequences(path, 'key')\n",
    "pass\n",
    "# sequences = read_sequences(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "data_paths = {\n",
    "    'train': '../Data/train_key',\n",
    "    'valid': '../Data/valid_key'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "# Data parsing\n",
    "from utils.DatasetGenerator import get_set\n",
    "datasets = {\n",
    "    'train': None,\n",
    "    'valid': None\n",
    "}\n",
    "\n",
    "for idx, set in enumerate(data_paths):\n",
    "    print(f'Converting {set} data')\n",
    "    data = get_set(data_paths[set], 'key', regenerate=True)\n",
    "    \n",
    "    datasets[set] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving train sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sequence generation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*weights_only=False.*\")\n",
    "from utils.DatasetGenerator import create_set_sequences, get_set_sequences\n",
    "from itertools import chain\n",
    "\n",
    "N = 10\n",
    "window = 500\n",
    "for idx, set in enumerate(datasets):\n",
    "    if len(datasets[set]) > 0:\n",
    "        print(f'Generating {set} sequences')\n",
    "        create_set_sequences(datasets[set], N, window, 'key')\n",
    "\n",
    "combined_train_key_input = None\n",
    "combined_train_key_target = None\n",
    "valid_sequences = None\n",
    "for idx, set in enumerate(data_paths):\n",
    "    print(f'Retrieving {set} sequences')\n",
    "    key_input_sequences, key_target_sequences = get_set_sequences(data_paths[set], 'key')\n",
    "    if set == 'train':\n",
    "        combined_train_key_input = list(chain.from_iterable(key_input_sequences))\n",
    "        combined_train_key_target = list(chain.from_iterable(key_target_sequences))\n",
    "    else:\n",
    "        valid_sequences = [key_input_sequences, key_target_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from Model.OSUDataset import OsuDataset, collate_fn\n",
    "data_paths = {\n",
    "    'train': '../Data/train_key',\n",
    "    'valid': '../Data/valid_key'\n",
    "}\n",
    "BATCH_SIZE_TRAIN = 512\n",
    "if os.path.exists('train_dataset.pth'):\n",
    "    train_dataset = torch.load('./key_dataset/train_dataset.pth')\n",
    "else:\n",
    "    train_dataset = OsuDataset(combined_train_key_input, combined_train_key_target)\n",
    "    torch.save(train_dataset, './key_dataset/train_dataset.pth')\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, drop_last=True, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "BATCH_SIZE_VALID = 64\n",
    "valid_loaders = []\n",
    "valid_folders = os.listdir(data_paths['valid'])\n",
    "valid_data_size = sum(os.path.isdir(os.path.join(data_paths['valid'], folder)) for folder in valid_folders)\n",
    "for idx in range(valid_data_size):\n",
    "    if os.path.exists(f'./key_dataset/valid_dataset_{idx}.pth'):\n",
    "        valid_dataset = torch.load(f'./key_dataset/valid_dataset_{idx}.pth')\n",
    "    else:\n",
    "        valid_dataset = valid_dataset = OsuDataset(valid_sequences[0][idx], valid_sequences[1][idx])\n",
    "        torch.save(valid_dataset, f'./key_dataset/valid_dataset_{idx}.pth')\n",
    "        \n",
    "    valid_loader =  DataLoader(valid_dataset, batch_size=BATCH_SIZE_VALID, shuffle=False, drop_last=True, collate_fn=collate_fn, pin_memory=True)\n",
    "    valid_loaders.append(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from Model.OSUModel import KeypressEncoder, KeypressDecoder, OSUModelKey\n",
    "key_input_size = 4\n",
    "key_hidden_size = 16\n",
    "key_num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "key_encoder = KeypressEncoder(key_input_size, key_hidden_size, key_num_layers).to(device)\n",
    "key_decoder = KeypressDecoder(key_hidden_size, key_num_layers).to(device)\n",
    "\n",
    "osuModelKey = OSUModelKey(key_encoder, key_decoder, device)\n",
    "key_criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "key_optimizer = torch.optim.Adam(\n",
    "    osuModelKey.parameters(),\n",
    "    lr=0.01,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "key_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(key_optimizer, mode='min',\n",
    "                                                    factor=0.1, patience=25,\n",
    "                                                    threshold=1e-4)\n",
    "\n",
    "def masked_loss_key(key_outputs, targets, target_lengths):    \n",
    "    # Keypress targets (batch_size, sequence_len - 1, num_keys)\n",
    "    key_targets = targets[:, 1:, :]\n",
    "    \n",
    "    # Creating mask for variable length sequences\n",
    "    max_len = key_outputs.size(1)\n",
    "    #(batch_size, max_len). True when value is less than target length\n",
    "    mask = torch.arange(max_len).unsqueeze(0) < target_lengths.unsqueeze(1) \n",
    "    mask = mask.to(key_outputs.device)\n",
    "    \n",
    "    # Keypress loss with cross entropy loss\n",
    "    key_targets_idx = torch.argmax(key_targets, dim=2)\n",
    "    key_loss = key_criterion(key_outputs.permute(0, 2, 1), key_targets_idx)\n",
    "    key_loss = (key_loss * mask).sum() / mask.sum()\n",
    "    \n",
    "    return key_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]T Loss Key: 0.4726 | V Loss Key: 0.4438 | LR Key: 0.01 | TFR: 1.00\n",
      "Epoch [2/1000]T Loss Key: 0.2352 | V Loss Key: 0.4173 | LR Key: 0.01 | TFR: 0.95\n",
      "Epoch [3/1000]T Loss Key: 0.1970 | V Loss Key: 0.4096 | LR Key: 0.01 | TFR: 0.90\n",
      "Epoch [4/1000]T Loss Key: 0.1694 | V Loss Key: 0.4696 | LR Key: 0.01 | TFR: 0.85\n",
      "Epoch [5/1000]T Loss Key: 0.1470 | V Loss Key: 0.4887 | LR Key: 0.01 | TFR: 0.80\n",
      "Epoch [6/1000]T Loss Key: 0.1349 | V Loss Key: 0.5573 | LR Key: 0.01 | TFR: 0.75\n",
      "Epoch [7/1000]T Loss Key: 0.1280 | V Loss Key: 0.3795 | LR Key: 0.01 | TFR: 0.70\n",
      "Epoch [8/1000]T Loss Key: 0.1210 | V Loss Key: 0.5004 | LR Key: 0.01 | TFR: 0.65\n",
      "Epoch [9/1000]T Loss Key: 0.1221 | V Loss Key: 0.4353 | LR Key: 0.01 | TFR: 0.60\n",
      "Epoch [10/1000]T Loss Key: 0.1164 | V Loss Key: 0.3981 | LR Key: 0.01 | TFR: 0.55\n",
      "Epoch [11/1000]T Loss Key: 0.1161 | V Loss Key: 0.3985 | LR Key: 0.01 | TFR: 0.50\n",
      "Epoch [12/1000]T Loss Key: 0.1111 | V Loss Key: 0.3093 | LR Key: 0.01 | TFR: 0.45\n",
      "Epoch [13/1000]T Loss Key: 0.1079 | V Loss Key: 0.3918 | LR Key: 0.01 | TFR: 0.40\n",
      "Epoch [14/1000]T Loss Key: 0.1092 | V Loss Key: 0.3493 | LR Key: 0.01 | TFR: 0.35\n",
      "Epoch [15/1000]T Loss Key: 0.1109 | V Loss Key: 0.3473 | LR Key: 0.01 | TFR: 0.30\n",
      "Epoch [16/1000]T Loss Key: 0.1069 | V Loss Key: 0.3166 | LR Key: 0.01 | TFR: 0.25\n",
      "Epoch [17/1000]T Loss Key: 0.1016 | V Loss Key: 0.3140 | LR Key: 0.01 | TFR: 0.20\n",
      "Epoch [18/1000]T Loss Key: 0.1022 | V Loss Key: 0.3197 | LR Key: 0.01 | TFR: 0.15\n",
      "Epoch [19/1000]T Loss Key: 0.1073 | V Loss Key: 0.3682 | LR Key: 0.01 | TFR: 0.10\n",
      "Epoch [20/1000]T Loss Key: 0.0990 | V Loss Key: 0.2865 | LR Key: 0.01 | TFR: 0.05\n",
      "Epoch [21/1000]T Loss Key: 0.0958 | V Loss Key: 0.3695 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [22/1000]T Loss Key: 0.0949 | V Loss Key: 0.3259 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [23/1000]T Loss Key: 0.0948 | V Loss Key: 0.3043 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [24/1000]T Loss Key: 0.0929 | V Loss Key: 0.2868 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [25/1000]T Loss Key: 0.0864 | V Loss Key: 0.2938 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [26/1000]T Loss Key: 0.0867 | V Loss Key: 0.2808 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [27/1000]T Loss Key: 0.0829 | V Loss Key: 0.2796 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [28/1000]T Loss Key: 0.0833 | V Loss Key: 0.2827 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [29/1000]T Loss Key: 0.0743 | V Loss Key: 0.2724 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [30/1000]T Loss Key: 0.0729 | V Loss Key: 0.2611 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [31/1000]T Loss Key: 0.0736 | V Loss Key: 0.3481 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [32/1000]T Loss Key: 0.0795 | V Loss Key: 0.2836 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [33/1000]T Loss Key: 0.0719 | V Loss Key: 0.2766 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [34/1000]T Loss Key: 0.0688 | V Loss Key: 0.3134 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [35/1000]T Loss Key: 0.0690 | V Loss Key: 0.2718 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [36/1000]T Loss Key: 0.0698 | V Loss Key: 0.2488 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [37/1000]T Loss Key: 0.0706 | V Loss Key: 0.2829 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [38/1000]T Loss Key: 0.0730 | V Loss Key: 0.3102 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [39/1000]T Loss Key: 0.0699 | V Loss Key: 0.2548 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [40/1000]T Loss Key: 0.0714 | V Loss Key: 0.3871 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [41/1000]T Loss Key: 0.0725 | V Loss Key: 0.2553 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [42/1000]T Loss Key: 0.0670 | V Loss Key: 0.2824 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [43/1000]T Loss Key: 0.0678 | V Loss Key: 0.2876 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [44/1000]T Loss Key: 0.0730 | V Loss Key: 0.2530 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [45/1000]T Loss Key: 0.0666 | V Loss Key: 0.2652 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [46/1000]T Loss Key: 0.0672 | V Loss Key: 0.2552 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [47/1000]T Loss Key: 0.0661 | V Loss Key: 0.2487 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [48/1000]T Loss Key: 0.0653 | V Loss Key: 0.2704 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [49/1000]T Loss Key: 0.0642 | V Loss Key: 0.2636 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [50/1000]T Loss Key: 0.0646 | V Loss Key: 0.2480 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [51/1000]T Loss Key: 0.0654 | V Loss Key: 0.3192 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [52/1000]T Loss Key: 0.0680 | V Loss Key: 0.2370 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [53/1000]T Loss Key: 0.0640 | V Loss Key: 0.2259 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [54/1000]T Loss Key: 0.0667 | V Loss Key: 0.3248 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [55/1000]T Loss Key: 0.0707 | V Loss Key: 0.3080 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [56/1000]T Loss Key: 0.0654 | V Loss Key: 0.2301 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [57/1000]T Loss Key: 0.0641 | V Loss Key: 0.2347 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [58/1000]T Loss Key: 0.0636 | V Loss Key: 0.2452 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [59/1000]T Loss Key: 0.0642 | V Loss Key: 0.2503 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [60/1000]T Loss Key: 0.0641 | V Loss Key: 0.2593 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [61/1000]T Loss Key: 0.0677 | V Loss Key: 0.2523 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [62/1000]T Loss Key: 0.0655 | V Loss Key: 0.2456 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [63/1000]T Loss Key: 0.0656 | V Loss Key: 0.2475 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [64/1000]T Loss Key: 0.0643 | V Loss Key: 0.2451 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [65/1000]T Loss Key: 0.0657 | V Loss Key: 0.2658 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [66/1000]T Loss Key: 0.0633 | V Loss Key: 0.2900 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [67/1000]T Loss Key: 0.0669 | V Loss Key: 0.2503 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [68/1000]T Loss Key: 0.0632 | V Loss Key: 0.2517 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [69/1000]T Loss Key: 0.0636 | V Loss Key: 0.2499 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [70/1000]T Loss Key: 0.0646 | V Loss Key: 0.2403 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [71/1000]T Loss Key: 0.0637 | V Loss Key: 0.2593 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [72/1000]T Loss Key: 0.0648 | V Loss Key: 0.2915 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [73/1000]T Loss Key: 0.0648 | V Loss Key: 0.2737 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [74/1000]T Loss Key: 0.0656 | V Loss Key: 0.2697 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [75/1000]T Loss Key: 0.0634 | V Loss Key: 0.2927 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [76/1000]T Loss Key: 0.0627 | V Loss Key: 0.2430 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [77/1000]T Loss Key: 0.0620 | V Loss Key: 0.2413 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [78/1000]T Loss Key: 0.0615 | V Loss Key: 0.2643 | LR Key: 0.01 | TFR: 0.00\n",
      "Epoch [79/1000]T Loss Key: 0.0630 | V Loss Key: 0.2542 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [80/1000]T Loss Key: 0.0602 | V Loss Key: 0.2480 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [81/1000]T Loss Key: 0.0586 | V Loss Key: 0.2473 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [82/1000]T Loss Key: 0.0586 | V Loss Key: 0.2299 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [83/1000]T Loss Key: 0.0584 | V Loss Key: 0.2409 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [84/1000]T Loss Key: 0.0585 | V Loss Key: 0.2397 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [85/1000]T Loss Key: 0.0582 | V Loss Key: 0.2410 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [86/1000]T Loss Key: 0.0584 | V Loss Key: 0.2487 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [87/1000]T Loss Key: 0.0581 | V Loss Key: 0.2412 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [88/1000]T Loss Key: 0.0580 | V Loss Key: 0.2390 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [89/1000]T Loss Key: 0.0578 | V Loss Key: 0.2452 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [90/1000]T Loss Key: 0.0578 | V Loss Key: 0.2427 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [91/1000]T Loss Key: 0.0574 | V Loss Key: 0.2440 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [92/1000]T Loss Key: 0.0580 | V Loss Key: 0.2478 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [93/1000]T Loss Key: 0.0577 | V Loss Key: 0.2364 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [94/1000]T Loss Key: 0.0580 | V Loss Key: 0.2463 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [95/1000]T Loss Key: 0.0581 | V Loss Key: 0.2354 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [96/1000]T Loss Key: 0.0575 | V Loss Key: 0.2414 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [97/1000]T Loss Key: 0.0577 | V Loss Key: 0.2461 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [98/1000]T Loss Key: 0.0575 | V Loss Key: 0.2394 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [99/1000]T Loss Key: 0.0576 | V Loss Key: 0.2469 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [100/1000]T Loss Key: 0.0572 | V Loss Key: 0.2407 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [101/1000]T Loss Key: 0.0572 | V Loss Key: 0.2437 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [102/1000]T Loss Key: 0.0578 | V Loss Key: 0.2464 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [103/1000]T Loss Key: 0.0576 | V Loss Key: 0.2451 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [104/1000]T Loss Key: 0.0571 | V Loss Key: 0.2449 | LR Key: 0.001 | TFR: 0.00\n",
      "Epoch [105/1000]T Loss Key: 0.0577 | V Loss Key: 0.2432 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [106/1000]T Loss Key: 0.0569 | V Loss Key: 0.2427 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [107/1000]T Loss Key: 0.0567 | V Loss Key: 0.2437 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [108/1000]T Loss Key: 0.0571 | V Loss Key: 0.2435 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [109/1000]T Loss Key: 0.0568 | V Loss Key: 0.2437 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [110/1000]T Loss Key: 0.0568 | V Loss Key: 0.2436 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [111/1000]T Loss Key: 0.0566 | V Loss Key: 0.2414 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [112/1000]T Loss Key: 0.0565 | V Loss Key: 0.2450 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [113/1000]T Loss Key: 0.0568 | V Loss Key: 0.2432 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [114/1000]T Loss Key: 0.0569 | V Loss Key: 0.2443 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [115/1000]T Loss Key: 0.0565 | V Loss Key: 0.2436 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [116/1000]T Loss Key: 0.0565 | V Loss Key: 0.2438 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [117/1000]T Loss Key: 0.0566 | V Loss Key: 0.2435 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [118/1000]T Loss Key: 0.0565 | V Loss Key: 0.2431 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [119/1000]T Loss Key: 0.0569 | V Loss Key: 0.2407 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [120/1000]T Loss Key: 0.0569 | V Loss Key: 0.2439 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [121/1000]T Loss Key: 0.0569 | V Loss Key: 0.2418 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [122/1000]T Loss Key: 0.0566 | V Loss Key: 0.2422 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [123/1000]T Loss Key: 0.0569 | V Loss Key: 0.2431 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [124/1000]T Loss Key: 0.0567 | V Loss Key: 0.2441 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [125/1000]T Loss Key: 0.0564 | V Loss Key: 0.2450 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [126/1000]T Loss Key: 0.0564 | V Loss Key: 0.2436 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [127/1000]T Loss Key: 0.0566 | V Loss Key: 0.2426 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [128/1000]T Loss Key: 0.0563 | V Loss Key: 0.2445 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [129/1000]T Loss Key: 0.0566 | V Loss Key: 0.2422 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [130/1000]T Loss Key: 0.0564 | V Loss Key: 0.2441 | LR Key: 0.0001 | TFR: 0.00\n",
      "Epoch [131/1000]T Loss Key: 0.0569 | V Loss Key: 0.2447 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [132/1000]T Loss Key: 0.0562 | V Loss Key: 0.2446 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [133/1000]T Loss Key: 0.0567 | V Loss Key: 0.2445 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [134/1000]T Loss Key: 0.0568 | V Loss Key: 0.2443 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [135/1000]T Loss Key: 0.0566 | V Loss Key: 0.2442 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [136/1000]T Loss Key: 0.0564 | V Loss Key: 0.2443 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [137/1000]T Loss Key: 0.0566 | V Loss Key: 0.2443 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [138/1000]T Loss Key: 0.0564 | V Loss Key: 0.2444 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [139/1000]T Loss Key: 0.0562 | V Loss Key: 0.2443 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [140/1000]T Loss Key: 0.0567 | V Loss Key: 0.2442 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [141/1000]T Loss Key: 0.0568 | V Loss Key: 0.2442 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [142/1000]T Loss Key: 0.0566 | V Loss Key: 0.2441 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [143/1000]T Loss Key: 0.0565 | V Loss Key: 0.2441 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [144/1000]T Loss Key: 0.0565 | V Loss Key: 0.2431 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [145/1000]T Loss Key: 0.0566 | V Loss Key: 0.2443 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [146/1000]T Loss Key: 0.0564 | V Loss Key: 0.2441 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [147/1000]T Loss Key: 0.0567 | V Loss Key: 0.2443 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [148/1000]T Loss Key: 0.0560 | V Loss Key: 0.2442 | LR Key: 1e-05 | TFR: 0.00\n",
      "Epoch [149/1000]T Loss Key: 0.0565 | V Loss Key: 0.2443 | LR Key: 1e-05 | TFR: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m key_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Forward propagate\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m train_key_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mosuModelKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n\u001b[0;32m     22\u001b[0m loss_key \u001b[38;5;241m=\u001b[39m masked_loss_key(train_key_outputs, train_targets, target_lengths)\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\Model\\OSUModel.py:147\u001b[0m, in \u001b[0;36mOSUModelKey.forward\u001b[1;34m(self, input, targets, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m    145\u001b[0m key_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m--> 147\u001b[0m     key_pred, key_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_decoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# Teacher forcing\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m teacher_forcing_ratio:\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\Model\\OSUModel.py:80\u001b[0m, in \u001b[0;36mKeypressDecoder.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# Forward pass through the LSTM\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(output)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Key press classification output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kq836\\source\\repos\\listener\\osu\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "total_train_len = len(train_loader)\n",
    "total_valid_len = 0\n",
    "for valid_loader in valid_loaders:\n",
    "    total_valid_len += len(valid_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    osuModelKey.train()\n",
    "    train_loss_key = 0\n",
    "    teacher_forcing_ratio = max(1 - (epoch / 20), 0)\n",
    "    \n",
    "    # Training\n",
    "    for train_inputs, train_targets, input_lengths, target_lengths in train_loader:\n",
    "        train_inputs, train_targets = train_inputs.to(device), train_targets.to(device)\n",
    "        \n",
    "        key_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagate\n",
    "        train_key_outputs = osuModelKey(train_inputs, train_targets, teacher_forcing_ratio)\n",
    "        \n",
    "        # Compute losses\n",
    "        loss_key = masked_loss_key(train_key_outputs, train_targets, target_lengths)\n",
    "        \n",
    "        # Accumulate losses\n",
    "        train_loss_key += loss_key.item()\n",
    "        \n",
    "        # Keypress encoder back propagation\n",
    "        loss_key.backward()\n",
    "        \n",
    "        # Gradient clipping \n",
    "        torch.nn.utils.clip_grad_norm_(osuModelKey.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Updating weights\n",
    "        key_optimizer.step()\n",
    "        \n",
    "    train_loss_key /= total_train_len\n",
    "    \n",
    "    # Validation\n",
    "    osuModelKey.eval()\n",
    "    total_valid_loss_key = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for valid_loader in valid_loaders:\n",
    "            valid_loss_pos = 0\n",
    "            valid_loss_key = 0\n",
    "            for valid_inputs, valid_targets, input_lengths, target_lengths in valid_loader:\n",
    "                valid_inputs, valid_targets = valid_inputs.to(device), valid_targets.to(device)\n",
    "\n",
    "                valid_key_outputs = osuModelKey(valid_inputs, valid_targets)\n",
    "                \n",
    "                loss_key = masked_loss_key(valid_key_outputs, valid_targets, target_lengths)\n",
    "                valid_loss_key += loss_key.item()\n",
    "                \n",
    "            total_valid_loss_key += valid_loss_key\n",
    "            \n",
    "    total_valid_loss_key /= total_valid_len\n",
    "    \n",
    "    key_scheduler.step(total_valid_loss_key)\n",
    "    \n",
    "    key_lr = key_optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Printing info\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\"\n",
    "    f\"T Loss Key: {train_loss_key:.4f} | \"\n",
    "    f\"V Loss Key: {total_valid_loss_key:.4f} | \"\n",
    "    f\"LR Key: {key_lr} | \"\n",
    "    f\"TFR: {teacher_forcing_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '0.3'\n",
    "torch.save(osuModelKey.state_dict(), f'./OSU_model_key_{VERSION}.pth')     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
